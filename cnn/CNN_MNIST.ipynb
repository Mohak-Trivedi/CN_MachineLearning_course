{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #tensorflow version 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-74c63d5ec704>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Neerva\\Documents\\coding_ninjas_ML\\35_cnn2\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Neerva\\Documents\\coding_ninjas_ML\\35_cnn2\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Neerva\\Documents\\coding_ninjas_ML\\35_cnn2\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Neerva\\Documents\\coding_ninjas_ML\\35_cnn2\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Neerva\\Documents\\coding_ninjas_ML\\35_cnn2\\env\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True) #Loading the data and doing one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of assigning values directly in architecture code, we'll declare constants, so that we can play with different \n",
    "#values for different parameters\n",
    "\n",
    "#input image is a 1d array of 784 element we'll convert into a 2d array having 28X28X1 dimensions. Thus, channels = 1\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32 #number of units in 1st convolutional layer\n",
    "n_conv2 = 64 #number of units in 2nd convolutional layer\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "k_conv1 = 5 #5X5 filter in 1st convolutional layer\n",
    "k_conv2 = 5 #5X5 filter in 2nd convolutional layer\n",
    "max_pool1_k = 2 #pool_size = 2 in 1st pooling layer\n",
    "max_pool2_k = 2 #pool_size = 2 in 2nd pooling layer\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) * n_conv2 #dimension of input coming into the hidden layer\n",
    "n_hidden = 1024 #number of units in dense layer\n",
    "n_out = 10 #number of units in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing weights\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([k_conv1, k_conv1, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([k_conv2, k_conv2, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "#initializing biases\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random_normal([n_out]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution function that will take in the image, weights, baises and the stride for filter, and gives us the transformed\n",
    "#image\n",
    "def conv(x, weights, bias, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding = \"SAME\", strides = [1, strides, strides, 1])#strides is an interesting argument \n",
    "    #as it requires a list[no_of_e.gs, stride_through_height, stride_through_width, stride_through_depth] of the same length\n",
    "    # as the number of values in x. And the dimension of x is given by: \n",
    "    #no_of_images_in_a_batch X height X width X no_of_channels. Thus, we pass 4 numbers into the strides argument.\n",
    "    #These 4 numbers basically represent by how much you want to move the filter.\n",
    "    #But, why do we take the 1st number as 1 and not as 100(in our case)? Because, we don't want to combine the images\n",
    "    #we want to move the filter according to stride through one image at a time, and we don't want to skip any image.\n",
    "    #Why do we keep the 4th number as 1? Because we don't want to move the filter along the depth, as that won't even\n",
    "    #happen acually, as we have taken our filter to be 3d as well having it's depth equal to the number of channels in an \n",
    "    #image.\n",
    "    #Now, we need to add the biases separately as TensorFlow's con2d doesn't include that. There's a special function\n",
    "    #in TensorFlow to add biases rather than using tf.nn.add(out, bias). This special function is different than tf.nn.add\n",
    "    #such that it allows us to add different kinds of dimensions,different kinds of types of vectors.\n",
    "    out = tf.nn.bias_add(out, bias)\n",
    "    #TensorFlow also allows us to use activation function  in convolution layer as well. We'll use RELU\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "#Now writing the max pooling function, that takes i/p from the convolution layer before it and uses max pooling according\n",
    "#to the pooling size and reduces the dimensions of the image.\n",
    "def maxpooling(x, k = 2): #k is the pool_size\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1])\n",
    "    #where ksize = [pool_size_across_images(we kept 1 as we want to have our pool's size sufficient to 1 pooling 1 image),\n",
    "    # height_of_pool, width_of_pool, depth_of_pool], and strides list format is same, except here we're talking about\n",
    "    #striding of max-pool and not a filter. We can keep strides value same mostly, or even different than stride of filter.\n",
    "    \n",
    "    \n",
    "#Notice that  if we change the padding in conv() & maxpooling() to “valid”, then we need to make changes in our code at:\n",
    "#weights of the hidden layer as well as we need to reshape before feeding into the hidden layer.\n",
    "\n",
    "#Notice that in maxpooling() if we keep tf.nn.max_pool(x, padding=\"SAME\", ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1])\n",
    "#and we have x say 28X28X1, then o/p would be 28X28X1, as whenever padding=\"SAME\" and striding is done by 1, o/p remains \n",
    "#the same.\n",
    "#and, for same x if we have tf.nn.max_pool(x, padding=\"valid\", ksize=[1, 3, 3, 1], strides=[1, 3, 3, 1]), then o/p will be\n",
    "#9X9X1 as through a 2d image we're doing 3X3 max-pooling and striding by 3X3. Thus, 28/3 X 28/3 X 1 = 9X9X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward propagation\n",
    "def cnn(x, weights, biases, keep_prob):#it will require the inputs, weights and biases and probability of keeping unit\n",
    "    #when they will go through the dropout layer.\n",
    "    #i/p from MNIST is an image represented as 1D array consisting of 784 elements, also, there isn't a single image we will\n",
    "    #get multiple images, and as we'll be using batch system we would have a batch size (how many images in a batch) say 550\n",
    "    #or let's take it as 100. So in a batch we'll be having 100 images of 784 pixels. We want the image to be represented as\n",
    "    #a 2D array, so we'll reshape 100X784 into 100X28X28X1 (1 because we have number of channels as 1 here, it might be \n",
    "    #another number in another case so we want to include that while reshaping)\n",
    "    x = tf.reshape(x, shape = [-1, input_height, input_width, input_channels]) #we know the three values but not the 4th one \n",
    "    #among reshape dimensions and we don't even need to know, as we're using reshape and we mentioned there -1, it will \n",
    "    #infer it.\n",
    "     \n",
    "    #The next step is to pass it to the convolutional layer1, we'll be using the same tensorflow code, but will be\n",
    "    #combining a few lines\n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1) #getting o/p of convolutional layer1\n",
    "    conv1_pool = maxpooling(conv1, max_pool1_k) #getting o/p of max pooling layer1\n",
    "    conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2) #getting o/p of convolutional layer2\n",
    "    conv2_pool = maxpooling(conv2, max_pool2_k) #getting o/p of max pooling layer2\n",
    "    \n",
    "    #Now the next layer is the dense layer, but, before passing forward to we need to reshape it into 1D array, as discussed\n",
    "    #in the notes\n",
    "    hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden]) #Here we don't need to explicitly mention the\n",
    "    #three remaining dimensions as we have already calculated their product and stored in input_size_to_hidden\n",
    "    #Now's the time to get the output from the dense layer. \n",
    "    #But, before applying the activation function we need to do the weighted summation and add biases as well. WX+B\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights['wh1']), biases['bh1'])\n",
    "    #Now getting the final o/p from the hidden layer by applying the RELU activation function (before it is passed to \n",
    "    #dropout layer.)\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    #Output of hidden layer that passes through dropout layer\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob)\n",
    "    \n",
    "    #Getting the o/p from the o/p layer. We are using the identity activation function i.e. no activation function in the\n",
    "    #o/p layer, just the weighted summation\n",
    "    output = tf.add(tf.matmul(hidden_output, weights['wo']), biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now our CNN is ready\n",
    "#Now we have to declare the x and y and then do the predictions using our CNN forward propagation\n",
    "#For this, the code is exactly same as that we wrote for mnist in ANN, just the names of variables differ.\n",
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.placeholder(\"float\", )\n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's get the cost. Same code as in ANN, but here we'll use _v2 at end to stop deprecation warning\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to do optimization. Same code copy-pasted from ANN.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "optimizer = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to initialize the variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we just need the code which will run the optimization code multiple times\n",
    "#copy-pasted as well (from ANN MNIST)\n",
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost, optimize], feed_dict = {x : batch_x, y : batch_y, keep_prob : 0.8})\n",
    "        total_cost += c\n",
    "    print(total_cost)\n",
    "#NOTE: This will take a LLLOOOOTTTTTT of time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to find accuracy on our test data\n",
    "#copy-pasted as well (from ANN MNIST)\n",
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions, correct_preds = sess.run([predictions, correct_predictions], feed_dict = {x : mnist.test.images, y : mnist.test.labels, keep_prob : 1.0})\n",
    "correct_preds.sum()\n",
    "#Remember: always have keep_prob:1 in case of testing data, also in training if you don't want dropout there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
