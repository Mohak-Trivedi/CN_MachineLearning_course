{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0, 1, 1, 0]]).T\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    return 1/(1 + np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSig(z):\n",
    "    return sig(z) * (1 - sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hidden layer weights\n",
    "wh = 2 * np.random.random((2, 2)) - 1\n",
    "bh = 2 * np.random.random((1, 2)) - 1\n",
    "wo = 2 * np.random.random((2, 1)) - 1\n",
    "bo = 2 * np.random.random((1, 1)) - 1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy-pasted weight updation code from no hidden layer n\n",
    "# for iter in range(10000):\n",
    "    \n",
    "#     output0 = X\n",
    "#     output = sig(np.dot(output0, weights) + bias)\n",
    "\n",
    "    \n",
    "#     first_term = output - Y #d(E)/d(Oj) = y_pred - y_actual\n",
    "#     input_for_last_layer = np.dot(output0, weights) + bias #i/p_j\n",
    "#     second_term = derivative_sig(input_for_last_layer) #d(Oj)/d(i/p_j) = sig(z)(1 - sig(z))\n",
    "#     first_two = first_term * second_term\n",
    "    \n",
    "#     changes = np.dot(output0.T, first_two)\n",
    "#     weights = weights - lr * changes\n",
    "    \n",
    "#     bias_change = np.sum(first_two)\n",
    "#     bias = bias - lr * bias_change\n",
    "    \n",
    "# output = sig(np.dot(X, weights) + bias)\n",
    "# weights, bias, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00285849],\n",
       "        [0.00273478],\n",
       "        [0.00325913],\n",
       "        [0.0032266 ]]),\n",
       " array([[ 0.70203961,  0.04272399],\n",
       "        [-0.5109873 ,  0.16277069]]),\n",
       " array([[1.15534798, 1.2030535 ]]),\n",
       " array([[1.08029964],\n",
       "        [2.48908394]]),\n",
       " array([[5.02104224]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward propagation with one hidden layer\n",
    "for iter in range(1000):\n",
    "    output0 = X\n",
    "    inputHidden = np.dot(output0, wh) + bh\n",
    "    outputHidden = sig(inputHidden)\n",
    "    inputForOutputLayer = np.dot(outputHidden, wo) + bo \n",
    "    output = sig(inputForOutputLayer)\n",
    "\n",
    "    first_term_output_layer = output - Y\n",
    "    second_term_output_layer = derivativeSig(inputForOutputLayer)\n",
    "    first_two_output_layer = first_term_output_layer * second_term_output_layer\n",
    "\n",
    "    #Backpropagating first_two_output_layer into hidden layer\n",
    "    first_term_hidden_layer = np.dot(first_two_output_layer, wo.T)\n",
    "    second_term_hidden_layer = derivativeSig(inputHidden)\n",
    "    first_two_hidden_layer = first_term_hidden_layer * second_term_hidden_layer\n",
    "\n",
    "    #from above cell you'll notice that to get the changes for the a layer we need to do dot product of current layer's first_two  with previous layer's o/p\n",
    "    changes_output = np.dot(outputHidden.T, first_two_output_layer)\n",
    "    #from above cell you'll notice that to get the bias_changes for the layer we need to sum the first_two of that layer\n",
    "    changes_output_bias = np.sum(first_two_output_layer, axis = 0, keepdims = True) #we also have to use parameter keepdims = True i.e. keep dimension, so that it maintains its dimensions as a vector instead of giving the sum simply as a single value, thus, we can do vector addition with the bias else it wouldn't be possible. Also, we use axis = 0 to specify in which axis it has to do addition\n",
    "\n",
    "    changes_hidden = np.dot(output0.T, first_two_hidden_layer)\n",
    "    changes_hidden_bias = np.sum(first_two_hidden_layer, axis = 0, keepdims = True)\n",
    "\n",
    "    #now let's do the actual changes\n",
    "    wo = wo - lr * changes_output\n",
    "    bo = bo - lr * changes_output_bias\n",
    "\n",
    "    wh = wh - lr * changes_hidden\n",
    "    bh = bh - lr * changes_hidden_bias\n",
    "    \n",
    "#Getting output again after updating weights optimally\n",
    "output0 = X\n",
    "inputHidden = np.dot(output0, wh) + bh\n",
    "outputHidden = sig(inputHidden)\n",
    "inputForOutputLayer = np.dot(outputHidden, wo) + bo \n",
    "output = sig(inputForOutputLayer)\n",
    "output, wh, bh, wo, bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have got the desired o/p. And if you use all these values and do manual calculation you'll notice that we have got the \n",
    "#units working in the same manner as we did in the initial lectures where we did XOR neural network by hand.\n",
    "#It's possible that if you run all this again, you might get different functions in the units, but the final o/p will be \n",
    "#almost same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus, we have successfully implemented a neural network having a hidden layer!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
