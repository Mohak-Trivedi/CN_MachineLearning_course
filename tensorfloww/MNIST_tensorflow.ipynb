{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #note: I'm using tensorflow version 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data #importing MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "fmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True) #Loading MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001E3160CCB48>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001E3160CC788>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001E3160CCB08>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist\n",
    "#in o/p you can see it says Datasets, because that is the datatype of fmnist. Also, it specifies that this dataset includes\n",
    "#trainig data, testing data and validation data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since, the dataset consists of images, let's see how many images are there in the trainig data\n",
    "#Also, we know that images are represented by encoding each of their pixels as an 2d-array element. However, here we have \n",
    "#flattened data i.e. represented in 1d array.\n",
    "#fmnist.train.images to view image arrays\n",
    "fmnist.train.images.shape\n",
    "#It contains 55,000 images,each represented by a 1d array of 784 elements, thus in 2d array it must be 28X28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.train.labels #labels in the training dataset\n",
    "#As you can see, each image's label is a digit (0 to 9) which is present in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a multi-class classification problem as there are more than 2 (i.e. 10) classes/labels here, thus, the o/p layer\n",
    "#of our neural network will have 10 units each will o/p 0 or 1 as each will represent a class. \n",
    "#e.g. o/p will be [0, 0, 0, 0, 0, 0, 0, 1, 0] if digit predicted is 8.\n",
    "#Thus, we need to do one-hot encoding of our Y data (label data)\n",
    "#We don't have to do it manually, just add parameter one_hot = true while loading the mnist dataset, and we're done\n",
    "#Now, if you run the fmnist.train.labels.shape, you won't get (55000,) instead (55000, 10), because now each of the 55000\n",
    "#rows contains an array which represents a digit in the same way in which we get the o/p from our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now, that we have our data ready in the required format, let's plot the images\n",
    "first_image = fmnist.train.images[0]\n",
    "#The problem while plotting this image is that the image is not a 2d array but it's a flattened image i.e. 1d array\n",
    "#So, let's unflatten it by reshaping the 1d arrays of 784 elements each into 2d arrays of dimension 28X28\n",
    "#We'll first make it an np array so that it becomes easy to reshape it.\n",
    "first_image = np.array(first_image, dtype = 'float')\n",
    "first_image = first_image.reshape((28, 28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()\n",
    "#This image has the digit 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is our first image in the training dataset, we can view others too if we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture of our neural network:-\n",
    "#As the images are in flattened format in 1d array each of 784 elements, thus each image that we feed to our neural network\n",
    "#we are acually feeding it 784 features as i/p, thus, our neural network will have 784 units in the i/p layer\n",
    "n_input = 784\n",
    "#And as discussed earlier our o/p layer will have 10 units\n",
    "n_classes = 10\n",
    "#How do we decide how many hidden layers to use and how many units in each of those hidden layers?\n",
    "#Let's just choose no. hidden layers to be 2\n",
    "#Also, there's no formula to calculate number of units to use in each hidden layer. Generally, we keep it in the same order\n",
    "#as that of i/p. Since, we have 784 i/p units, we'll pick a value between 100 to 1000. Let's take 256 for both hidden layers\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "#Also, we'll be having 3 biases: 1 in i/p layer, 1 in hidden layer1, 1 in hidden layer 2\n",
    "#Number of weights in hidden layer1 (i.e. going from i/p layer to hidden layer) will be 784*256\n",
    "#Number of bias weights in hidden layer1 will be 1*256 = 256\n",
    "#Number of weights in hidden layer2 (i.e. going from hidden layer1 to hidden layer2) will be 256*256\n",
    "#Number of bias weights in hidden layer2 will be 1*256 = 256\n",
    "#Number of weights in o/p layer (i.e. going from hidden layer2 to o/p layer) will be 256*10\n",
    "#Number of bias weights in o/p layer will be 1*256 = 256\n",
    "\n",
    "#Architecture of weights and biases\n",
    "#Instead of storing these as n_hidden1_weight, n_hidden2_weight, n_hidden1_bias, etc.. We will create a single variable named\n",
    "#weights which will contain a dictionary of weights in each layer.\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])), #tf.random_normal([dimensions]) returns random values in the mentioned dimensions from a normal distribution \n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes])),\n",
    "}\n",
    "biases = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes])),\n",
    "}\n",
    "\n",
    "#To store all these values we don't use tf.constants because these values are going to change over time\n",
    "#To store all these values we don't use tf.placeholder because we won't enter these values by getting i/p from the user\n",
    "#We use tf.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propagation\n",
    "def forward_propagation(x, weights, biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x, weights['h1']), biases['h1']) #net(total) input going into hidden layer1 (remember WX + B)\n",
    "    out_layer1 = tf.nn.relu(in_layer1) #output of hidden layer1. We are using RELU activation function in each unit of hidden layer1\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1, weights['h2']), biases['h2'])#net(total) input going into hidden layer2\n",
    "    out_layer2 = tf.nn.relu(in_layer2) #output of hidden layer2. We are using RELU activation function in each unit of hidden layer2\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2, weights['out']), biases['out'])#net(total) input going into o/p layer\n",
    "    return output #Identity activation function (No specific activation function) in output layer unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before going ahead and finding the optimal values of weights, let's use these random weight values and do forward propagation\n",
    "#and find out y_pred i.e. output and check its accuracy.\n",
    "#We can pass the weights and biases as arguments because we have already defined what they are above., but, ww haven't \n",
    "#defined what x is, as x could sometimes be training data, sometimes be testing data or validation data.\n",
    "#Thus, we should use placeholder to define x\n",
    "#As we do know that no matter what x is, it's dimensions will be (None(bcoz each will have different no. of images))X(no_of_features), thus we use the shape parameter of placeholder\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "#Similartly we can define y, each o/p is a vector of size 10 (= no. of classes)\n",
    "y = tf.placeholder(\"int32\", [None, n_classes])\n",
    "\n",
    "pred = forward_propagation(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In tensorflow,we don't need to update the weights manually. We just have to find the cost and then use any in-built\n",
    "#optimizer which will optimize the weights.\n",
    "#Let's define the cost function\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y)  #We will use the cross-entropy error function to calculate the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We don't want the error to be an array of values which show the error in each label's prediction for each image.\n",
    "#We need a single value\n",
    "#So, let's take the mean\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll use any of the in-built optimizers to do backpropagation and optimize the weights, which we were doing manually,\n",
    "#when we were not using tensorflow\n",
    "optimizer =  tf.train.AdamOptimizer(learning_rate = 0.01)\n",
    "#As we want the optimizer to optimize in such a way that it minimizes the cost\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us now remove the previously created session and then re run the notebook and then create a new fresh session\n",
    "#And thus initialize everything again and run all the predictions again\n",
    "#And then also run the cost function which we created and then also run the optimizer and get the optimized weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we need to initialize all the variables (weights, biases, etc..) which we had just declared but not initialized\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Now, we have the o/p in pred, which is an array containing an array of size 10 for each o/p.\n",
    "# #We want to know the index containing the highest value. That index is the digit that is predicted in case of that particular array\n",
    "# predictions = tf.argmax(pred, 1) #tf.max will return the maximum value from the array, but, argmax will return the index at which the maximum valued element is present.\n",
    "# #We have also passed 1 as an argument because it is the axis i.e. it tells that we need index of maximum value from each array present in the array pred\n",
    "# true_labels = tf.argmax(y, 1)\n",
    "# #Thus, we have all the digits predicted by our neural network stored in 'predictions', and all the digits which are our y_actual in correct_labels\n",
    "# correct_predictions = tf.equal(predictions, true_labels) #To see whether our predictions are same as the actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Now, let's make the predictions, and also evaluate the labels and also the correct_predictions\n",
    "# predictions_eval, labels, correct_pred = sess.run([predictions, true_labels, correct_predictions], feed_dict = {x:fmnist.train.images, y:fmnist.train.labels})\n",
    "# #We need to feed x to evaluate predictions, and y to evaluate labels\n",
    "# predictions_eval, labels, correct_pred\n",
    "# #Each time you run this cell, you'll get a different o/p as each time initialization is happening. Thus, shifting the \n",
    "# #initialization code to one of the above cells\n",
    "# #Now, we'll get the same predictions each time you run this cell\n",
    "\n",
    "# #Wherever you're getting a true -> correct prediction, false -> incorrect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #To see number of correct predictions\n",
    "# correct_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(25): \n",
    "#     c, _ = sess.run([cost, optimize], feed_dict={x:fmnist.train.images, y:fmnist.train.labels}) #since we're calling 2 things we\n",
    "#     #need 2 things on the left of =, as we won't be using the second thing, we just name it _, we're doing it just for the sake \n",
    "#     #of providing the second thing\n",
    "#     print(c)\n",
    "#     #Now, if you run it second time you'll see a much lesser value of cost (c) as we have also called optimize which optimizes \n",
    "#     #the weights each time we run this cell. If you run just once, you'll get the unoptimized cost. Thus, to run it multiple\n",
    "#     #times, let's use a loop.\n",
    "#     #Note that, there's no guarantee that the error will just go on decreasing as we iterate again and again, it may increase\n",
    "#     #or decrease depending upon the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25218.526025295258\n",
      "4734.448161499173\n",
      "2574.7900358829734\n",
      "1819.3838437007291\n",
      "1346.2928699476502\n",
      "1186.1116715537717\n",
      "1066.7967991355274\n",
      "870.2685128161651\n",
      "887.8457492822466\n",
      "632.010648095446\n",
      "651.0599048831956\n",
      "615.5070192349236\n",
      "481.15489542786685\n",
      "530.501262331319\n",
      "402.39424967730076\n",
      "306.00140325062654\n",
      "241.1070828425345\n",
      "285.87195891328554\n",
      "247.8861956161068\n",
      "239.24912589204902\n",
      "213.766886587986\n",
      "155.14901219525865\n",
      "145.54262537622938\n",
      "92.91391068375833\n",
      "117.83691822408434\n"
     ]
    }
   ],
   "source": [
    "#Instead of iterating 25 times on the entire training dataset like above, we will use batch gradient descent(refer notes)\n",
    "#where batch size is 100. Training data consists of 55000 images, thus we will have 55000/100 = 550 batches.\n",
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(fmnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = fmnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost, optimize], feed_dict={x:batch_x, y:batch_y}) #since we're calling 2 things we\n",
    "        #need 2 things on the left of =, as we won't be using the second thing, we just name it _, we're doing it just for the sake \n",
    "        #of providing the second thing\n",
    "        total_cost += c\n",
    "    print(total_cost)\n",
    "        #Now, if you run it second time you'll see a much lesser value of cost (c) as we have also called optimize which optimizes \n",
    "        #the weights each time we run this cell. If you run just once, you'll get the unoptimized cost. Thus, to run it multiple\n",
    "        #times, let's use a loop.\n",
    "        #Note that, there's no guarantee that the error will just go on decreasing as we iterate again and again, it may increase\n",
    "        #or decrease depending upon the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53786"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, that we have optimized our neural network let's use it to make predictions\n",
    "#Now, we have the o/p in pred, which is an array containing an array of size 10 for each o/p.\n",
    "#We want to know the index containing the highest value. That index is the digit that is predicted in case of that particular array\n",
    "predictions = tf.argmax(pred, 1) #tf.max will return the maximum value from the array, but, argmax will return the index at which the maximum valued element is present.\n",
    "#We have also passed 1 as an argument because it is the axis i.e. it tells that we need index of maximum value from each array present in the array pred\n",
    "true_labels = tf.argmax(y, 1)\n",
    "#Thus, we have all the digits predicted by our neural network stored in 'predictions', and all the digits which are our y_actual in correct_labels\n",
    "correct_predictions = tf.equal(predictions, true_labels) #To see whether our predictions are same as the actual labels\n",
    "\n",
    "#Now, let's make the predictions, and also evaluate the labels and also the correct_predictions\n",
    "predictions_eval, labels, correct_pred = sess.run([predictions, true_labels, correct_predictions], feed_dict = {x:fmnist.train.images, y:fmnist.train.labels})\n",
    "#We need to feed x to evaluate predictions, and y to evaluate labels\n",
    "predictions_eval, labels, correct_pred\n",
    "#Each time you run this cell, you'll get a different o/p as each time initialization is happening. Thus, shifting the \n",
    "#initialization code to one of the above cells\n",
    "#Now, we'll get the same predictions each time you run this cell\n",
    "#Wherever you're getting a true -> correct prediction, false -> incorrect prediction\n",
    "\n",
    "#To see number of correct predictions\n",
    "correct_pred.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
