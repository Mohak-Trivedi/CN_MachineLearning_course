{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#We'll use Sequential Model and Dense Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a model:\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the architecture of model:\n",
    "#We'll have 2 hidden layers(1st having 32 units and 2nd having 16 units, both using relu activation function) and 1 o/p \n",
    "#layer having 1 unit using sigmoid activation function\n",
    "\n",
    "layer1 = Dense(units = 32, activation = 'relu', input_dim = 30) #defining hidden layer 1; input_dim = units in i/p layer = \n",
    "#features in the dataset\n",
    "model.add(layer1) #adding the hidden layer 1 into our model\n",
    "\n",
    "model.add(Dense(units = 16, activation = 'relu')) #Defining hidden layer2 as well as adding it to our model;No need to \n",
    "#mention input_dim as Keras does that automatically except for 1st hidden layer\n",
    "\n",
    "model.add(Dense(units = 1, activation = 'sigmoid')) #Defining o/p layer as well as adding it to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile:\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#Since, we'll be doing binary classification we're using binary cross entropy cost function. We're using accuracy as a metric\n",
    "#We chose adamBoost as the optimizer which will minimize the value of our cost function by optimizing the neural network.\n",
    "#Choosing the correct accuracy function is important for the compile function because it will be printed during fit and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to do the next step i.e. fit, we need to get the dataset. We'll be using breast cancer dataset.\n",
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing\n",
    "#(refer feature scaling notes)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/20\n",
      "455/455 [==============================] - 6s 12ms/step - loss: 0.8048 - accuracy: 0.4615 - val_loss: 0.6701 - val_accuracy: 0.6491\n",
      "Epoch 2/20\n",
      "455/455 [==============================] - 0s 330us/step - loss: 0.6094 - accuracy: 0.7253 - val_loss: 0.5220 - val_accuracy: 0.8246\n",
      "Epoch 3/20\n",
      "455/455 [==============================] - 0s 562us/step - loss: 0.4787 - accuracy: 0.8835 - val_loss: 0.4141 - val_accuracy: 0.9211\n",
      "Epoch 4/20\n",
      "455/455 [==============================] - 0s 669us/step - loss: 0.3811 - accuracy: 0.9407 - val_loss: 0.3353 - val_accuracy: 0.9386\n",
      "Epoch 5/20\n",
      "455/455 [==============================] - 0s 520us/step - loss: 0.3060 - accuracy: 0.9451 - val_loss: 0.2785 - val_accuracy: 0.9386\n",
      "Epoch 6/20\n",
      "455/455 [==============================] - 0s 402us/step - loss: 0.2508 - accuracy: 0.9538 - val_loss: 0.2368 - val_accuracy: 0.9386\n",
      "Epoch 7/20\n",
      "455/455 [==============================] - 0s 456us/step - loss: 0.2088 - accuracy: 0.9604 - val_loss: 0.2047 - val_accuracy: 0.9474\n",
      "Epoch 8/20\n",
      "455/455 [==============================] - 0s 438us/step - loss: 0.1756 - accuracy: 0.9648 - val_loss: 0.1802 - val_accuracy: 0.9386\n",
      "Epoch 9/20\n",
      "455/455 [==============================] - 0s 367us/step - loss: 0.1516 - accuracy: 0.9714 - val_loss: 0.1625 - val_accuracy: 0.9386\n",
      "Epoch 10/20\n",
      "455/455 [==============================] - 0s 341us/step - loss: 0.1333 - accuracy: 0.9714 - val_loss: 0.1486 - val_accuracy: 0.9386\n",
      "Epoch 11/20\n",
      "455/455 [==============================] - 0s 360us/step - loss: 0.1187 - accuracy: 0.9736 - val_loss: 0.1371 - val_accuracy: 0.9386\n",
      "Epoch 12/20\n",
      "455/455 [==============================] - 0s 460us/step - loss: 0.1073 - accuracy: 0.9780 - val_loss: 0.1277 - val_accuracy: 0.9386\n",
      "Epoch 13/20\n",
      "455/455 [==============================] - 0s 320us/step - loss: 0.0982 - accuracy: 0.9780 - val_loss: 0.1197 - val_accuracy: 0.9298\n",
      "Epoch 14/20\n",
      "455/455 [==============================] - 0s 428us/step - loss: 0.0910 - accuracy: 0.9802 - val_loss: 0.1149 - val_accuracy: 0.9298\n",
      "Epoch 15/20\n",
      "455/455 [==============================] - 0s 373us/step - loss: 0.0850 - accuracy: 0.9802 - val_loss: 0.1101 - val_accuracy: 0.9298\n",
      "Epoch 16/20\n",
      "455/455 [==============================] - 0s 473us/step - loss: 0.0806 - accuracy: 0.9846 - val_loss: 0.1055 - val_accuracy: 0.9474\n",
      "Epoch 17/20\n",
      "455/455 [==============================] - 0s 326us/step - loss: 0.0766 - accuracy: 0.9846 - val_loss: 0.1025 - val_accuracy: 0.9474\n",
      "Epoch 18/20\n",
      "455/455 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.98 - 0s 392us/step - loss: 0.0734 - accuracy: 0.9846 - val_loss: 0.0989 - val_accuracy: 0.9474\n",
      "Epoch 19/20\n",
      "455/455 [==============================] - 0s 268us/step - loss: 0.0702 - accuracy: 0.9868 - val_loss: 0.0972 - val_accuracy: 0.9561\n",
      "Epoch 20/20\n",
      "455/455 [==============================] - 0s 436us/step - loss: 0.0679 - accuracy: 0.9868 - val_loss: 0.0949 - val_accuracy: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x29bb5f5cc48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit:\n",
    "model.fit(x_train, y_train, epochs = 20, batch_size = 50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see for trainig data we have 98.68% accuracy and for testing data we have 95.61% accuracy.\n",
    "#Also, as expected for each epoch we're getting the loss function value and accuracy for both training as well as validation\n",
    "#dataset\n",
    "#Remember that we're fitting the model only on the trainig data, the validation_data (here, testing data) is only for \n",
    "#Checking score on it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4791952e-02],\n",
       "       [9.7429252e-01],\n",
       "       [9.9849463e-01],\n",
       "       [9.9556714e-01],\n",
       "       [9.9773359e-01],\n",
       "       [9.9257213e-01],\n",
       "       [9.9897921e-01],\n",
       "       [9.9477911e-01],\n",
       "       [9.9990058e-01],\n",
       "       [9.9996769e-01],\n",
       "       [7.7550834e-01],\n",
       "       [9.4804472e-01],\n",
       "       [9.9981505e-01],\n",
       "       [5.7856327e-01],\n",
       "       [5.2198088e-01],\n",
       "       [4.5723666e-02],\n",
       "       [9.9573416e-01],\n",
       "       [1.2819531e-03],\n",
       "       [6.2750294e-03],\n",
       "       [9.3624672e-05],\n",
       "       [3.2536928e-02],\n",
       "       [2.6188359e-02],\n",
       "       [9.7186905e-01],\n",
       "       [9.9692684e-01],\n",
       "       [8.1788115e-03],\n",
       "       [9.9782121e-01],\n",
       "       [9.9986589e-01],\n",
       "       [8.0941897e-03],\n",
       "       [9.9744654e-01],\n",
       "       [9.2549337e-04],\n",
       "       [9.9976081e-01],\n",
       "       [1.5484474e-02],\n",
       "       [7.8456557e-01],\n",
       "       [1.8285709e-02],\n",
       "       [9.9997222e-01],\n",
       "       [1.8123150e-02],\n",
       "       [9.8769379e-01],\n",
       "       [3.0445235e-02],\n",
       "       [9.9044305e-01],\n",
       "       [4.2660780e-02],\n",
       "       [5.3948373e-01],\n",
       "       [9.9976271e-01],\n",
       "       [3.8585234e-01],\n",
       "       [9.9955302e-01],\n",
       "       [9.2637581e-01],\n",
       "       [7.5130331e-05],\n",
       "       [9.9999082e-01],\n",
       "       [9.8031884e-01],\n",
       "       [9.9597013e-01],\n",
       "       [2.1095744e-03],\n",
       "       [1.3572288e-03],\n",
       "       [5.6874529e-02],\n",
       "       [6.1646313e-03],\n",
       "       [9.9745721e-01],\n",
       "       [9.9222517e-01],\n",
       "       [9.9928755e-01],\n",
       "       [9.9812073e-01],\n",
       "       [9.9813604e-01],\n",
       "       [9.8855698e-01],\n",
       "       [5.6714176e-05],\n",
       "       [7.6382875e-02],\n",
       "       [2.6042357e-02],\n",
       "       [9.9974805e-01],\n",
       "       [9.8059756e-01],\n",
       "       [5.7867006e-03],\n",
       "       [9.5890695e-01],\n",
       "       [1.3019246e-07],\n",
       "       [3.6345303e-04],\n",
       "       [7.1955117e-04],\n",
       "       [9.9794096e-01],\n",
       "       [5.3055686e-01],\n",
       "       [1.7168541e-03],\n",
       "       [9.9423754e-01],\n",
       "       [2.5605613e-01],\n",
       "       [4.4243879e-04],\n",
       "       [9.8976552e-01],\n",
       "       [9.9983144e-01],\n",
       "       [9.0398991e-01],\n",
       "       [9.9958366e-01],\n",
       "       [9.9980873e-01],\n",
       "       [4.4396829e-02],\n",
       "       [3.6694651e-06],\n",
       "       [1.9813569e-03],\n",
       "       [9.9963474e-01],\n",
       "       [4.8149195e-02],\n",
       "       [9.9739480e-01],\n",
       "       [9.9979168e-01],\n",
       "       [9.9993515e-01],\n",
       "       [4.3333550e-03],\n",
       "       [1.5613668e-06],\n",
       "       [9.9985075e-01],\n",
       "       [6.9232357e-01],\n",
       "       [3.1683102e-01],\n",
       "       [3.3653146e-04],\n",
       "       [9.9872774e-01],\n",
       "       [9.9407393e-01],\n",
       "       [4.0455381e-04],\n",
       "       [9.8381400e-01],\n",
       "       [9.8007411e-01],\n",
       "       [9.9145526e-01],\n",
       "       [9.9999774e-01],\n",
       "       [9.9187744e-01],\n",
       "       [9.9062485e-01],\n",
       "       [8.1511152e-01],\n",
       "       [5.1628426e-03],\n",
       "       [9.9029189e-01],\n",
       "       [2.4159302e-04],\n",
       "       [7.8400087e-01],\n",
       "       [8.0843991e-01],\n",
       "       [7.1414423e-01],\n",
       "       [9.4844037e-01],\n",
       "       [1.2774415e-03],\n",
       "       [5.4269508e-03],\n",
       "       [9.4330090e-01]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction:\n",
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 263us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09487668751624592, 0.9561403393745422]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate (i.e. get score):\n",
    "score = model.evaluate(x_test, y_test) #No need to do in our case, as we had passed test data as validation_data in fit()\n",
    "score\n",
    "#We get the final loss function value and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
