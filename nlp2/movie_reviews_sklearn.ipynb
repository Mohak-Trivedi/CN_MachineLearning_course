{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll see how to change the format of data from the one which is suitable for nltk classifiers to the one which is \n",
    "#suitable for sklearn classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #this will help us in acheiving our goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = {\"the sky is blue\", \"the sun is bright\"}\n",
    "\n",
    "#to get the features we will go through each word and get a list of most frequently occuring words and those would be our features.\n",
    "#we don't have to do that manually, we'll do it this way:\n",
    "#however, this function does not clean  the  data for us, we need to feed it already cleaned data, here we haven't\n",
    "count_vec = CountVectorizer(max_features = 3) # go through the train_set and find the top 3 words(3 most frequent) and make them features. It converts each document(separated by commas in curly braces) in train_set into a row which represents the frequency in that document of the words selected as features.\n",
    "#Thus, a lot of values in each record would be 0 as not all the words are present in all the documents. Thus, we will get a sparse matrix i.e. a matrix in which many values are 0.\n",
    "#So, it's internally storing it in a most efficient manner so that it does not  need to store all those 0s\n",
    "a = count_vec.fit_transform(train_set)#fit and transform. the transformed version is then stored in a\n",
    "a # a is sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1],\n",
       "        [1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to look at the sparse matrix stored in a:\n",
    "a.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue', 'is', 'the']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this doesn't tell us much, so we have a function which will make things pretty\n",
    "count_vec.get_feature_names() #this shows us the features which are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing above two cells we can see:\n",
    "#'blue' is present in the first doc, but not in the second doc. 'is' and 'the' are present in both the docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
